{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7dc982e-bc6f-43fd-83ed-57351c55575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "W0000 00:00:1729645731.034658    9496 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1729645731.046824    9496 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "\n",
    "# Inicializar Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# Función para procesar una imagen y extraer los puntos faciales y datos de imagen\n",
    "def procesar_imagen(image_path):\n",
    "    # Cargar la imagen\n",
    "    image = cv2.imread(image_path)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detectar puntos faciales\n",
    "    results = face_mesh.process(rgb_image)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0]\n",
    "        \n",
    "        # Extraer puntos específicos del rostro\n",
    "        puntos_faciales = {\n",
    "            'left_eye_center': (landmarks.landmark[33].x, landmarks.landmark[33].y),\n",
    "            'right_eye_center': (landmarks.landmark[263].x, landmarks.landmark[263].y),\n",
    "            'nose_tip': (landmarks.landmark[1].x, landmarks.landmark[1].y),\n",
    "            'mouth_left_corner': (landmarks.landmark[78].x, landmarks.landmark[78].y),\n",
    "            'mouth_right_corner': (landmarks.landmark[308].x, landmarks.landmark[308].y),\n",
    "            'mouth_center_top_lip': (landmarks.landmark[13].x, landmarks.landmark[13].y),\n",
    "            'mouth_center_bottom_lip': (landmarks.landmark[14].x, landmarks.landmark[14].y)\n",
    "        }\n",
    "\n",
    "        # Convertir coordenadas de proporciones a píxeles\n",
    "        for key, (x, y) in puntos_faciales.items():\n",
    "            puntos_faciales[key] = (int(x * image.shape[1]), int(y * image.shape[0]))\n",
    "\n",
    "        # Convertir la imagen a una cadena de píxeles\n",
    "        image_flattened = image.flatten().tolist()  # Aplanar la imagen para guardarla como una lista\n",
    "        image_data_str = \" \".join(map(str, image_flattened))  # Convertir lista a string\n",
    "        \n",
    "        return puntos_faciales, image_data_str\n",
    "    else:\n",
    "        print(\"No se detectaron puntos faciales.\")\n",
    "        return None, None\n",
    "\n",
    "# Ruta al archivo CSV existente o nuevo\n",
    "csv_file_path = \"data_nuevo.csv\"\n",
    "\n",
    "# Procesar una nueva imagen\n",
    "image_path = \"imagenes/Lariza.jpeg\"  # Cambia por la ruta a tu imagen\n",
    "puntos_faciales, image_data_str = procesar_imagen(image_path)\n",
    "\n",
    "if puntos_faciales:\n",
    "    # Escribir una nueva línea en el CSV con los puntos faciales y datos de imagen\n",
    "    with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Estructura de la fila: incluye las coordenadas de cada punto facial\n",
    "        fila = [\n",
    "            puntos_faciales['left_eye_center'][0], puntos_faciales['left_eye_center'][1],\n",
    "            puntos_faciales['right_eye_center'][0], puntos_faciales['right_eye_center'][1],\n",
    "            puntos_faciales['nose_tip'][0], puntos_faciales['nose_tip'][1],\n",
    "            puntos_faciales['mouth_left_corner'][0], puntos_faciales['mouth_left_corner'][1],\n",
    "            puntos_faciales['mouth_right_corner'][0], puntos_faciales['mouth_right_corner'][1],\n",
    "            puntos_faciales['mouth_center_top_lip'][0], puntos_faciales['mouth_center_top_lip'][1],\n",
    "            puntos_faciales['mouth_center_bottom_lip'][0], puntos_faciales['mouth_center_bottom_lip'][1],\n",
    "            image_data_str  # Los datos de la imagen\n",
    "        ]\n",
    "        \n",
    "        writer.writerow(fila)\n",
    "else:\n",
    "    print(\"No se pudo procesar la imagen.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02d70169-f2cf-434b-9a3f-509e619d3803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "csv_file_path = \"dataset/data_nuevo.csv\"  # Cambia por la ruta de tu archivo CSV\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(data.head())\n",
    "\n",
    "# Si deseas visualizar un número específico de filas (por ejemplo, las primeras 10)\n",
    "print(data.head(10))\n",
    "\n",
    "# Si deseas ver la información general del dataset (columnas, tipos de datos, etc.)\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20872a55-6ce5-4936-b0bc-8bb7e68da998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
